<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>On Transportation of Mini-batches: A Hierarchical Approach | Son Nguyen</title> <meta name="author" content="Son Nguyen"> <meta name="description" content="Son Nguyen's homepage "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%87%A9%E2%80%8B&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/https://github.com/nguyendangson/nguyendangson.github.io/assets/css/main.css"> <link rel="canonical" href="https://nguyendangson.github.io/https://github.com/nguyendangson/nguyendangson.github.io/blog/2022/BoMbOT/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/https://github.com/nguyendangson/nguyendangson.github.io/assets/js/theme.js"></script> <script src="/https://github.com/nguyendangson/nguyendangson.github.io/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://github.com/nguyendangson/nguyendangson.github.io/" rel="external nofollow noopener" target="_blank"><span class="font-weight-bold">Son </span> Nguyen</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/https://github.com/nguyendangson/nguyendangson.github.io/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/https://github.com/nguyendangson/nguyendangson.github.io/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/https://github.com/nguyendangson/nguyendangson.github.io/cv/">Resume</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">On Transportation of Mini-batches: A Hierarchical Approach</h1> <p class="post-meta">August 26, 2022</p> <p class="post-tags"> <a href="https://github.com/nguyendangson/nguyendangson.github.io/blog/2022" rel="external nofollow noopener" target="_blank"> <i class="fas fa-calendar fa-sm"></i> 2022 </a>   ·   <a href="https://github.com/nguyendangson/nguyendangson.github.io/blog/tag/optimal-transport" rel="external nofollow noopener" target="_blank"> <i class="fas fa-hashtag fa-sm"></i> optimal-transport</a>   <a href="https://github.com/nguyendangson/nguyendangson.github.io/blog/tag/domain-adaptation" rel="external nofollow noopener" target="_blank"> <i class="fas fa-hashtag fa-sm"></i> domain-adaptation</a>   <a href="https://github.com/nguyendangson/nguyendangson.github.io/blog/tag/generative-models" rel="external nofollow noopener" target="_blank"> <i class="fas fa-hashtag fa-sm"></i> generative-models</a>     ·   <a href="https://github.com/nguyendangson/nguyendangson.github.io/blog/category/conference" rel="external nofollow noopener" target="_blank"> <i class="fas fa-tag fa-sm"></i> conference</a>   </p> </header> <article class="post-content"> <p><strong>Table of contents</strong></p> <ul> <li><a href="#introduction">Introduction</a></li> <li> <a href="#background">Background</a> <ul> <li><a href="#optimal-transport">Optimal Transport</a></li> <li><a href="#mini-batch-optimal-transport">Mini-batch Optimal Transport</a></li> </ul> </li> <li><a href="#batch-of-mini-batches-optimal-transport">Batch of Mini-batches Optimal Transport</a></li> <li><a href="#experiments">Experiments</a></li> <li><a href="#conclusion">Conclusion</a></li> <li><a href="#references">References</a></li> </ul> <h2 id="introduction">Introduction</h2> <p>The Optimal Transport (OT) theory has a long history in Applied mathematics and economics, and recently it has become a useful tool in machine learning applications such as deep generative models [1], domain adaptation [2], etc. Despite its popularity in ML, there are still major issues with using OT in large-scale datasets, those issues could be demonstrated in two following situations: “<strong>What if the number of supports is very large, for example millions?</strong>” and “<strong>What if the computation of optimal transport is repeated multiple times and has limited memory e.g., in deep learning?</strong>”. To deal with those problems, practitioners often replace the original large-scale computation of OT with cheaper computation on subsets of the whole dataset, which is widely referred to as mini-batch approaches [3, 4]. In particular, a min-batch is a sparse representation of the data. Despite being applied successfully, the current mini-batch OT loss does not consider the relationship between mini-batches and treats every pair of mini-batches the same. This causes undesirable effects in measuring the discrepancy between probability measures. First, the m-OT loss is shown to be an approximation of a discrepancy (the population m-OT) that does not preserve the metricity property, namely, this discrepancy is always positive even when two probability measures are identical. Second, it is also unclear whether this discrepancy achieves the minimum value when the two probability measures are the same. That naturally raises the question of whether we could propose a better mini-batch scheme to sort out these issues to improve the performance of the OT in applications.</p> <h2 id="background">Background</h2> <h3 id="optimal-transport">Optimal Transport</h3> <p>Let \(\mu, \nu\) be discrete distributions of $n$ supports, i.e. \(\mu := \frac{1}{n} \sum_{i=1}^n \delta_{x_i}\) and \(\nu := \frac{1}{n}\sum_{j=1}^{n} \delta_{y_j}\). Given distances between supports of two distributions as a matrix \(C\), the Optimal Transport (OT) problem reads:</p> \[\begin{equation} \text{OT}(\mu, \nu) = \min_{\pi \in \Pi(\mu, \nu)} \langle C,\pi \rangle \end{equation}\] <p>where \(\Pi(\mu, \nu) = \{ \pi \in \mathbb{R}_{+}^{n \times n} \mid \pi 1 = \mu, \pi^T 1 = \nu \}\) is the set of admissible transportation plans between \(\mu\) and \(\nu\).</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/https://github.com/nguyendangson/nguyendangson.github.io/assets/img/ot_example-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/https://github.com/nguyendangson/nguyendangson.github.io/assets/img/ot_example-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/https://github.com/nguyendangson/nguyendangson.github.io/assets/img/ot_example-1400.webp"></source> <img src="/https://github.com/nguyendangson/nguyendangson.github.io/assets/img/ot_example.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p style="text-align:center; font-style: italic">Figure 1. An example of OT with \(n = 4\).</p> <h3 id="mini-batch-optimal-transport">Mini-batch Optimal Transport</h3> <p>The original \(n\) samples are divided into random mini-batches of size \(m \geq 1\), then an alternative solution to the original OT problem is formed by averaging these smaller OT solutions.</p> \[\begin{equation} \text{m-OT}^m(\mu, \nu) = \mathbb{E}_{(X, Y) \sim \overset{\otimes m}{\mu} \otimes \overset{\otimes m}{\nu}} [\text{OT}(P_X, P_Y)] \end{equation}\] <p>where \(\otimes\) denotes product measure, \(X = (x_1, \ldots, x_m)\) is the sampled mini-batch, and \(P_X = \frac{1}{m} \sum_{i=1}^m \delta_{x_i}\) is the corresponding discrete distribution. In practice, we can use subsampling to approximate the expectation, thus the empirical m-OT reads:</p> \[\begin{equation} \text{m-OT}_k^m(\mu, \nu) \approx \frac{1}{k} \sum_{i=1}^k [\text{OT}(P_{X_i}, P_{Y_i})] \end{equation}\] <p>where \((X_1, Y_1), \ldots, (X_k, Y_k) \sim \overset{\otimes m}{\mu} \otimes \overset{\otimes m}{\nu}\) and \(k\) is often set to 1 in previous works.</p> <p><strong>Issue of m-OT:</strong> We can see that the optimal matchings at the mini-batch level in Figure 2 are different from the full-scale optimal transport. One source of the issue is that all pairs of mini-batches are treated the same.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/https://github.com/nguyendangson/nguyendangson.github.io/assets/img/mot_example2-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/https://github.com/nguyendangson/nguyendangson.github.io/assets/img/mot_example2-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/https://github.com/nguyendangson/nguyendangson.github.io/assets/img/mot_example2-1400.webp"></source> <img src="/https://github.com/nguyendangson/nguyendangson.github.io/assets/img/mot_example2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p style="text-align:center; font-style: italic">Figure 2. An example of m-OT with \(n = 4, m = 2\) and \(k = 2\).</p> <h2 id="batch-of-mini-batches-optimal-transport">Batch of Mini-batches Optimal Transport</h2> <p>To address the issues of m-OT, we solve an additional OT problem between mini-batches to find an optimal weighting for combining local mini-batch losses.</p> \[\begin{equation} \text{BoMb-OT}^m(\mu, \nu) = \inf_{\gamma \in \Gamma(\overset{\otimes m}{\mu} \otimes \overset{\otimes m}{\nu})} \mathbb{E}_{(X, Y) \sim \gamma} [\text{OT}(P_X, P_Y)] \end{equation}\] <p>where \(\otimes\) denotes product measure, \(X = (x_1, \ldots, x_m)\) is the sampled mini-batch, and \(P_X = \frac{1}{m} \sum_{i=1}^m \delta_{x_i}\) is the corresponding discrete distribution. In practice, we can use subsampling to approximate the expectation, thus the empirical BoMb-OT reads:</p> \[\begin{equation} \text{BoMb-OT}_k^m(\mu, \nu) \approx \inf_{\gamma \in \Gamma(\overset{\otimes m}{\mu_k} \otimes \overset{\otimes m}{\nu_k})} \sum_{i=1}^k \sum_{j=1}^k \gamma_{ij}[\text{OT}(P_{X_i}, P_{Y_j})] \end{equation}\] <p>where \(X_1, \ldots, X_k \sim \overset{\otimes m}{\mu}\) and \(\overset{\otimes m}{\mu_k} = \frac{1}{k} \sum_{i=1}^k \delta_{X_i}\). \(Y_j (1 \leq j \leq k)\) and \(\overset{\otimes m}{\nu_k}\) are defined similarly.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/https://github.com/nguyendangson/nguyendangson.github.io/assets/img/bombot_example-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/https://github.com/nguyendangson/nguyendangson.github.io/assets/img/bombot_example-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/https://github.com/nguyendangson/nguyendangson.github.io/assets/img/bombot_example-1400.webp"></source> <img src="/https://github.com/nguyendangson/nguyendangson.github.io/assets/img/bombot_example.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p style="text-align:center; font-style: italic">Figure 3. An example of BoMb-OT with \(n = 4, m = 2\) and \(k = 2\). After solving the OT problem between mini-batches, \(X_1\) is mapped to \(Y_2\) and \(X_2\) is mapped to \(Y_1\), which results in the same solution as the full-scale optimal transport.</p> <p><strong>Training deep networks with BoMb-OT loss:</strong> In the deep learning context, the supports are usually parameterized by neural networks. In addition, the gradient of neural networks is accumulated from each pair of mini-batches and only one pair of mini-batches are used in memory at a time. Since the computations on pairs of mini-batches are independent, we can use multiple devices to compute them. We propose a three-step algorithm to train neural networks with BoMb-OT loss as follows.</p> <p><img src="/assets/img/training_bombot_loss.png" alt="training_bombot_loss" style="display:block; margin-left:auto; margin-right:auto"></p> <h2 id="experiments">Experiments</h2> <p>BoMb-(U)OT shows a favorable performance compared to m-(U)OT on three types of applications, namely, <em>gradient-based</em> (e.g., deep generative model, deep domain adaptation (DA)), <em>mapping-based</em> (e.g., color transfer), and <em>value-based</em> (e.g., approximate Bayesian computation (ABC)).</p> <p style="text-align:center; font-style: italic"><img src="/assets/img/generative_model.png" alt="generative_model" style="display:block; margin-left:auto; margin-right:auto"> Table 1. Comparison between the BoMb-OT and the m-OT on deep generative models. On the MNIST dataset, we evaluate the performances of generators by computing approximated Wasserstein-2 while we use the FID score on CIFAR10 and CelebA.</p> <p style="text-align:center; font-style: italic"><img src="/assets/img/BoMbOT_DA_VisDA.png" alt="BoMbOT_DA_VisDA" style="display:block; margin-left:auto; margin-right:auto"> Table 2. Comparison between two mini-batch schemes on the deep domain adaptation on the VisDA dataset. We varied the number of mini-batches k and reported the classification accuracy on the target domain.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/https://github.com/nguyendangson/nguyendangson.github.io/assets/img/color_transfer-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/https://github.com/nguyendangson/nguyendangson.github.io/assets/img/color_transfer-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/https://github.com/nguyendangson/nguyendangson.github.io/assets/img/color_transfer-1400.webp"></source> <img src="/https://github.com/nguyendangson/nguyendangson.github.io/assets/img/color_transfer.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p style="text-align:center; font-style: italic">Figure 4. Experimental results on color transfer for full OT, the m-OT, and the BoMb-OT on natural images with \((k; m) = (10; 10)\). Color palettes are shown under corresponding images.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/https://github.com/nguyendangson/nguyendangson.github.io/assets/img/ABC-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/https://github.com/nguyendangson/nguyendangson.github.io/assets/img/ABC-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/https://github.com/nguyendangson/nguyendangson.github.io/assets/img/ABC-1400.webp"></source> <img src="/https://github.com/nguyendangson/nguyendangson.github.io/assets/img/ABC.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p style="text-align:center; font-style: italic">Figure 5. Approximated posteriors from ABC with the m-OT and the BoMb-OT. The first row, the second row, and the last row have \(m = 8, m = 16\), and \(m = 32\), respectively. In each row, the number of mini-batches k is 2; 4; 6; and 8 from left to right.</p> <h2 id="conclusion">Conclusion</h2> <p>In this paper, we have presented a novel mini-batch method for optimal transport, named Batch of Mini-batches Optimal Transport (BoMb-OT). The idea of the BoMb-OT is to consider the optimal transport problem on the space of mini-batches with an OT-types ground metric. More importantly, we have shown that the BoMb-OT can be implemented efficiently and they have more favorable performance than the m-OT in various applications of optimal transport including deep generative models, deep domain adaptation, color transfer, approximate Bayesian computation, and gradient flow. For future work, we could consider a hierarchical approach version of optimal transport between incomparable spaces. For further information, please refer to our work at <a href="https://proceedings.mlr.press/v162/nguyen22d/nguyen22d.pdf" rel="external nofollow noopener" target="_blank">https://proceedings.mlr.press/v162/nguyen22d/nguyen22d.pdf</a>.</p> <h2 id="references">References</h2> <p>[1] Arjovsky, M., Chintala, S., and Bottou, L. Wasserstein generative adversarial networks. In International Conference on Machine Learning, pp. 214–223, 2017.</p> <p>[2] Courty, N., Flamary, R., Tuia, D., and Rakotomamonjy, A. Optimal transport for domain adaptation. IEEE transactions on pattern analysis and machine intelligence, 39(9):1853–1865, 2016.</p> <p>[3] Fatras, K., Zine, Y., Flamary, R., Gribonval, R., and Courty, N. Learning with minibatch Wasserstein: asymptotic and gradient properties. In AISTATS 2020-23nd International Conference on Artificial Intelligence and Statistics, volume 108, pp. 1–20, 2020.</p> <p>[4] Fatras, K., Zine, Y., Majewski, S., Flamary, R., Gribonval, R., and Courty, N. Minibatch optimal transport distances; analysis and applications. arXiv preprint arXiv:2101.01792, 2021b.</p> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Son Nguyen. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/https://github.com/nguyendangson/nguyendangson.github.io/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/https://github.com/nguyendangson/nguyendangson.github.io/assets/js/zoom.js"></script> <script defer src="/https://github.com/nguyendangson/nguyendangson.github.io/assets/js/common.js"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>